{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ee07bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gregormilligan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import configparser\n",
    "import pandas as pd\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "import regex as re\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "nltk.download('stopwords')\n",
    "stop=set(stopwords.words('english'))\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc9192d0",
   "metadata": {},
   "outputs": [],
   "source": [
    " # read configs\n",
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']\n",
    "\n",
    "# authentication\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be059834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['user_name','tweet','created_at']\n",
    "kier_df = pd.DataFrame()\n",
    "kier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c00a9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent_boris_tweets():\n",
    "    boris_data=[]\n",
    "    boris_keywords = ['Boris Johnson','boris johnson']\n",
    "    limit = 300\n",
    "    boris_tweets = tweepy.Cursor(api.search_tweets, q=boris_keywords, count=100, tweet_mode='extended').items(limit)\n",
    "    columns = ['user_name','tweet']\n",
    "    for tweet in boris_tweets:\n",
    "        boris_data.append([tweet.user.screen_name, tweet.full_text])\n",
    "    global boris_df\n",
    "    boris_df = pd.DataFrame(boris_data,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e45a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent_kier_tweets():\n",
    "    kier_data = []\n",
    "    kier_keywords = ['Kier Starmer', 'kier starmer']\n",
    "    limit = 300\n",
    "    kier_tweets = tweepy.Cursor(api.search_tweets, q=kier_keywords, count=100, tweet_mode='extended').items(limit)\n",
    "    columns = ['user_name','tweet','created_at']\n",
    "    for tweet in kier_tweets:\n",
    "        kier_data.append([tweet.user.screen_name, tweet.full_text, tweet.created_at])\n",
    "    placeholder_df = pd.DataFrame(kier_data,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8272039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recent_kier_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a7cb0190",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'placeholder_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplaceholder_df\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'placeholder_df' is not defined"
     ]
    }
   ],
   "source": [
    "placeholder_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea14e498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning text\n",
    "import regex as re\n",
    "def cleanTxt(text):\n",
    "    df.drop_duplicates()\n",
    "    text = re.sub(r'@[A-Za-z0-9]+','',text) #removes @mentions\n",
    "    text = re.sub(r'#','',text)#removes #\n",
    "    text = re.sub(r'RT[\\s]','', text)#removes RTs\n",
    "    text = re.sub('https?:\\/\\/\\S+','',text)#removes hyperlinks  \n",
    "    #text = re.sub(r'[^A-Za-z]+', '', text)\n",
    "    return text\n",
    "df['Tweet'] = df['Tweet'].apply(cleanTxt)\n",
    "#show clean text\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "#Creating a function to get the subjectivity (How opinionated the text is)\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "#polarity of the tweets positive negative or neutral \n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "df['Subjectivity'] = df['Tweet'].apply(getSubjectivity)\n",
    "df['Polarity'] = df['Tweet'].apply(getPolarity)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b00fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "#visualise tweets in a wordcloud\n",
    "all_words = ' '.join([tweets for tweets in df['Tweet']])\n",
    "wordcloud = WordCloud(width = 500, height = 500, random_state=21, max_font_size= 119, stopwords=STOPWORDS).generate(all_words)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#find examples of negative sentiment and polarity and show those wcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c841dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAnalysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        return 'Positive'\n",
    "df['Analysis'] = df['Polarity'].apply(getAnalysis)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7e2f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedDF = df.sort_values(by=['Polarity'])\n",
    "sortedDF.to_excel('train_example2.xlsx')\n",
    "sortedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623eceb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee052ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get top 100 worst and do a wordcloud\n",
    "#visualise tweets in a wordcloud\n",
    "all_words = ' '.join([tweets for tweets in sortedDF['Tweet'][0:100]])\n",
    "wordcloud = WordCloud(width = 500, height = 500, random_state=21, max_font_size= 119, stopwords=STOPWORDS).generate(all_words)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ec5ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "for i in range(0,df.shape[0]):\n",
    "    plt.scatter(df['Polarity'][i], df['Subjectivity'][i], color=\"violet\")\n",
    "    \n",
    "plt.title(\"Railway Sentiment Analysis\")\n",
    "plt.xlabel(\"Polarity\")\n",
    "plt.ylabel(\"Subjectivty\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba5d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "df['Analysis'].value_counts()\n",
    "plt.title('Sentiment Analysis')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Counts')\n",
    "\n",
    "df['Analysis'].value_counts().plot(kind='bar', color=['mediumseagreen','lightsteelblue', 'indianred'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab994df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the corpus\n",
    "corpus=[]\n",
    "tweets = df['Tweet'].str.split()\n",
    "tweets=tweets.values.tolist()\n",
    "corpus=[word for i in tweets for word in i]\n",
    "\n",
    "from collections import defaultdict\n",
    "dic=defaultdict(int)\n",
    "for word in corpus:\n",
    "    if word in stop:\n",
    "        dic[word]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82b19a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_stopwords_barchart(text):\n",
    "    stop=set(stopwords.words('english'))\n",
    "    \n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "    from collections import defaultdict\n",
    "    dic=defaultdict(int)\n",
    "    for word in corpus:\n",
    "        if word in stop:\n",
    "            dic[word]+=1\n",
    "            \n",
    "    top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "    x,y=zip(*top)\n",
    "    \n",
    "    plt.barh(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f931e537",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_top_stopwords_barchart(df['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac6de35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "nltk.download('stopwords')\n",
    "stop=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9803a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def commonWordPlot(text):\n",
    "    \n",
    "    counter=Counter(text)\n",
    "    most=counter.most_common()\n",
    "\n",
    "    x, y= [], []\n",
    "    for word,count in most[:40]:\n",
    "        if (word not in stop):\n",
    "            x.append(word)\n",
    "            y.append(count)\n",
    "        \n",
    "    sns.barplot(x=y,y=x)\n",
    "commonWordPlot(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1780039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_tweets = api.home_timeline()\n",
    "columns = ['Tweet']\n",
    "data = []\n",
    "for tweet in public_tweets:\n",
    "    data.append(tweet.text)\n",
    "df = pd.DataFrame(data,columns=columns)\n",
    "df    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a19169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
